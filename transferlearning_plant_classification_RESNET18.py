# -*- coding: utf-8 -*-
"""TransferLearning_Plant_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16J5yp_lqLC9cEqiGr1-lQYBkNXCsadkD
"""

import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

torch.manual_seed(42)
transform = transforms.Compose(
        [transforms.Resize((128, 128)),
          transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_data = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/Bilkent/CS464 (1)/Plant_Dataset/Train', transform=transform)
train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers = 4, pin_memory=True)

validation_data = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/Bilkent/CS464 (1)/Plant_Dataset/Validation', transform=transform)
validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=15, shuffle=False, num_workers = 4, pin_memory=True)

test_data = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/Bilkent/CS464 (1)/Plant_Dataset/Test', transform=transform)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers = 4)

from google.colab import drive
drive.mount('/content/drive')

!pip install optuna

#Hyperparameter tuning
import optuna

def objective(trial):
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)  # Learning rate
    batch_size = trial.suggest_int('batch_size', 16, 32, 64, log=True)  # Batch size

    train_loader = torch.utils.data.DataLoader(
        train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True
    )

    # Define the model and optimizer
    model = torchvision.models.resnet18(pretrained=True)
    for param in model.parameters():
        param.requires_grad = False
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    model = model.to(device)

    optimizer = optim.Adam(model.fc.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    # Training loop for a fixed number of epochs
    epochs = 10  # Shortened for tuning
    best_validation_loss = float('inf')

    for epoch in range(epochs):
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        # Validation phase
        model.eval()
        validation_loss = 0
        with torch.no_grad():
            for inputs, labels in validation_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                validation_loss += loss.item()

        validation_loss /= len(validation_loader)

        # Early stopping: return the validation loss
        if validation_loss < best_validation_loss:
            best_validation_loss = validation_loss

    return best_validation_loss

# Create the study and optimize
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=20)

# Print best hyperparameters
print("Best hyperparameters:", study.best_params)

model = torchvision.models.resnet18(pretrained=True)

# Freeze all parameters
for param in model.parameters():
    param.requires_grad = False

# Replace the final fully connected layer
num_classes = len(train_data.classes)
model.fc = nn.Linear(model.fc.in_features, num_classes)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.0005)
epochs = 20
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

import os
import torch



best_model_path = "/content/drive/MyDrive/Bilkent/CS464 (1)/tl_best_model.pth"
all_models_dir = "/content/drive/MyDrive/Bilkent/CS464 (1)/all_models"
os.makedirs(all_models_dir, exist_ok=True)  # Ensure directory exists

best_validation_loss = float('inf')  # Initialize to a very high value

for epoch in range(epochs):
    model.train()
    train_loss_epoch = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()

        optimizer.step()
        train_loss_epoch += loss.item()

    print(f"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss_epoch / len(train_loader):.4f}")

    # Validation phase
    model.eval()
    validation_loss_epoch = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in validation_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            validation_loss_epoch += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    validation_loss = validation_loss_epoch / len(validation_loader)
    validation_accuracy = 100 * correct / total

    print(f"Epoch {epoch + 1}/{epochs}, Validation Loss: {validation_loss:.4f}")
    print(f"Validation Accuracy: {validation_accuracy:.2f}%")

    # Save the model for the current epoch
    epoch_model_path = os.path.join(all_models_dir, f"model_epoch_{epoch + 1}.pth")
    torch.save(model.state_dict(), epoch_model_path)
    print(f"Model for epoch {epoch + 1} saved to {epoch_model_path}")

    # Check if this is the best validation loss so far
    if validation_loss < best_validation_loss:
        best_validation_loss = validation_loss
        torch.save(model.state_dict(), best_model_path)  # Save best model parameters
        print(f"Best model saved with validation loss: {best_validation_loss:.4f}")

print("Training complete.")

model.eval()
test_loss = 0
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        test_loss += loss.item()

        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

test_accuracy = 100 * correct / total
print(f"Test Loss: {test_loss / len(test_loader):.4f}")
print(f"Test Accuracy: {test_accuracy:.2f}%")

best_model_path = "/content/drive/MyDrive/Bilkent/CS464 (1)/tl_best_model.pth"

# Define class names (update as per your dataset)
class_names = ["Healthy", "Powdery Mildew", "Rust"]
def evaluate_model(model_path, model, criterion, test_loader, device):
    # Load the saved model
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    test_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    test_accuracy = 100 * correct / total
    print(f"Test Loss: {test_loss / len(test_loader):.4f}")
    print(f"Test Accuracy: {test_accuracy:.2f}%")
    return test_loss / len(test_loader), test_accuracy


# Evaluate the best model
print("Evaluating the best model:")
evaluate_model(best_model_path, model, criterion, test_loader, device)

from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd
import seaborn as sns

def evaluate_model_with_metrics(model_path, model, criterion, test_loader, device, class_names):
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    test_loss = 0
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    test_accuracy = 100 * correct / total
    print(f"Test Loss: {test_loss / len(test_loader):.4f}")
    print(f"Test Accuracy: {test_accuracy:.2f}%")

    cm = confusion_matrix(all_labels, all_predictions)
    report = classification_report(all_labels, all_predictions, target_names=class_names, output_dict=True)
    metrics_df = pd.DataFrame(report).transpose()
    metrics_df = metrics_df[["precision", "recall", "f1-score", "support"]]
    print("\nClass-wise Performance Metrics:")
    print(metrics_df)
    print("\nConfusion Matrix:")
    print(cm)

    return test_loss / len(test_loader), test_accuracy, metrics_df, cm

# Evaluate the best model
print("Evaluating the best model:")
best_model_loss, best_model_accuracy, metrics_df, cm = evaluate_model_with_metrics(
    best_model_path, model, nn.CrossEntropyLoss(), test_loader, device, class_names
)

# Display metrics table
# Print the class-wise performance metrics
print("\nClass-wise Performance Metrics:")
print(metrics_df)

# Save the metrics to a CSV file
metrics_df.to_csv("class_performance_metrics.csv", index=True)

# Display confusion matrix using matplotlib and seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()